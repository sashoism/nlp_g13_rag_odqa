{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c17e897-34d2-4ea1-a73e-6ecebbb13f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Imports\n",
    "\n",
    "import re\n",
    "import random\n",
    "from itertools import filterfalse\n",
    "from collections import Counter\n",
    "import evaluate\n",
    "import ollama\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "random.seed(1718308331)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5951b61-358f-439f-a61a-4f70af2095ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Metrics\n",
    "\n",
    "exact_match = evaluate.load(\"exact_match\")\n",
    "\n",
    "\n",
    "def calculate_metrics(prediction, ground_truth):\n",
    "    prediction_tokens = re.findall(r\"\\w+\", prediction.lower())\n",
    "    ground_truth_tokens = re.findall(r\"\\w+\", ground_truth.lower())\n",
    "\n",
    "    common_tokens = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "\n",
    "    num_common_tokens = sum(common_tokens.values())\n",
    "\n",
    "    if len(prediction_tokens) == 0:\n",
    "        precision = 0.0\n",
    "    else:\n",
    "        precision = num_common_tokens / len(prediction_tokens)\n",
    "\n",
    "    if len(ground_truth_tokens) == 0:\n",
    "        recall = 0.0\n",
    "    else:\n",
    "        recall = num_common_tokens / len(ground_truth_tokens)\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        f1 = 0.0\n",
    "    else:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a6ddc9c-d040-4725-b2ff-7e7adbfbd7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% Prepare llama3 with temperature=0.5\n",
    "\n",
    "modelfile = \"\"\"\n",
    "FROM llama3\n",
    "PARAMETER temperature 0.5\n",
    "PARAMETER seed 1718308331\n",
    "\"\"\"\n",
    "\n",
    "ollama.create(model=\"llama3-temp0.5\", modelfile=modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c470ac46-c648-4cd9-bfbb-85834b46d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Load test data\n",
    "\n",
    "df = pd.read_json(\"dataset/data/dev.json\").head(1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b46e9f6d-9c8d-4d77-bf54-738d2644305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Make prompt\n",
    "\n",
    "def make_prompt(question, context, supporting_facts, top_k=None):\n",
    "    supporting_titles = {title for (title, _) in supporting_facts}\n",
    "\n",
    "    def is_oracle(evidence):\n",
    "        (title,_) = evidence\n",
    "        return title in supporting_titles\n",
    "\n",
    "    contexts = list(filter(is_oracle, context))\n",
    "    random.shuffle(contexts)\n",
    "\n",
    "    if top_k is not None:\n",
    "        negatives = list(filterfalse(is_oracle, context))\n",
    "        random.shuffle(negatives)\n",
    "        contexts.extend(negatives)\n",
    "        contexts = contexts[:top_k]\n",
    "\n",
    "    contexts = [\n",
    "        f\"Context {i}: [{title}] {' '.join(texts)}\"\n",
    "        for i, (title, texts) in enumerate(contexts, start=1)\n",
    "    ]\n",
    "\n",
    "    return \"\\n\\n\".join(\n",
    "        (\n",
    "            \"Please answer the given question based on the given contexts below.\",\n",
    "            *contexts,\n",
    "            f\"Question: {question}\",\n",
    "            \"Constraint: Don't give any explanations and use MAX 5 tokens in your response. No yapping.\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Run experiment and save results\n",
    "\n",
    "results = []\n",
    "for row in tqdm(df.itertuples()):\n",
    "    for top_k in (None, 1, 3, 5):\n",
    "        prompt = make_prompt(row.question, row.context, row.supporting_facts, top_k=top_k)\n",
    "        prediction = ollama.generate(model=\"llama3-temp0.5\", prompt=prompt)\n",
    "        results.append((top_k, row.question, row.answer, prediction[\"response\"]))\n",
    "\n",
    "pd.DataFrame(results, columns=(\"top_k\", \"question\", \"answer\", \"prediction\")).to_csv(\"oracle_prediction_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea6b6660-cc87-4f8d-b1ba-85e086568827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_k</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n/a</td>\n",
       "      <td>Who is the mother of the director of film Poli...</td>\n",
       "      <td>Małgorzata Braunek</td>\n",
       "      <td>Małgorzata Braunek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Who is the mother of the director of film Poli...</td>\n",
       "      <td>Małgorzata Braunek</td>\n",
       "      <td>Małgorzata Braunek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Who is the mother of the director of film Poli...</td>\n",
       "      <td>Małgorzata Braunek</td>\n",
       "      <td>Małgorzata Braunek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Who is the mother of the director of film Poli...</td>\n",
       "      <td>Małgorzata Braunek</td>\n",
       "      <td>Małgorzata Braunek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n/a</td>\n",
       "      <td>Which film came out first, Blind Shaft or The ...</td>\n",
       "      <td>The Mask Of Fu Manchu</td>\n",
       "      <td>The Mask of Fu Manchu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Do both My Friend From The Park and Punks (Fil...</td>\n",
       "      <td>no</td>\n",
       "      <td>No, they don't.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>n/a</td>\n",
       "      <td>Which country the director of film Romanoff An...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Which country the director of film Romanoff An...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Which country the director of film Romanoff An...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Which country the director of film Romanoff An...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4800 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     top_k                                           question  \\\n",
       "0      n/a  Who is the mother of the director of film Poli...   \n",
       "1      1.0  Who is the mother of the director of film Poli...   \n",
       "2      3.0  Who is the mother of the director of film Poli...   \n",
       "3      5.0  Who is the mother of the director of film Poli...   \n",
       "4      n/a  Which film came out first, Blind Shaft or The ...   \n",
       "...    ...                                                ...   \n",
       "4795   5.0  Do both My Friend From The Park and Punks (Fil...   \n",
       "4796   n/a  Which country the director of film Romanoff An...   \n",
       "4797   1.0  Which country the director of film Romanoff An...   \n",
       "4798   3.0  Which country the director of film Romanoff An...   \n",
       "4799   5.0  Which country the director of film Romanoff An...   \n",
       "\n",
       "                     answer              prediction  \n",
       "0        Małgorzata Braunek      Małgorzata Braunek  \n",
       "1        Małgorzata Braunek      Małgorzata Braunek  \n",
       "2        Małgorzata Braunek      Małgorzata Braunek  \n",
       "3        Małgorzata Braunek      Małgorzata Braunek  \n",
       "4     The Mask Of Fu Manchu  The Mask of Fu Manchu.  \n",
       "...                     ...                     ...  \n",
       "4795                     no         No, they don't.  \n",
       "4796         United Kingdom                 England  \n",
       "4797         United Kingdom                 England  \n",
       "4798         United Kingdom                American  \n",
       "4799         United Kingdom                 England  \n",
       "\n",
       "[4800 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% Reload results\n",
    "\n",
    "results_df = pd.read_csv(\"oracle_prediction_results.csv\")\n",
    "results_df[\"top_k\"] = results_df[\"top_k\"].astype(str).replace(\"nan\", \"n/a\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1d832e4-6fe4-452a-b43b-eaa3d4400d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_203181/4192359711.py:13: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  \"EM\": results_df.groupby(\"top_k\").apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_k</th>\n",
       "      <th>EM</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.335833</td>\n",
       "      <td>0.434792</td>\n",
       "      <td>0.440234</td>\n",
       "      <td>0.425343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.405833</td>\n",
       "      <td>0.563333</td>\n",
       "      <td>0.617513</td>\n",
       "      <td>0.570063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.537408</td>\n",
       "      <td>0.611012</td>\n",
       "      <td>0.551896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n/a</td>\n",
       "      <td>0.484167</td>\n",
       "      <td>0.638940</td>\n",
       "      <td>0.696369</td>\n",
       "      <td>0.644686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  top_k        EM  Precision    Recall        F1\n",
       "0   1.0  0.335833   0.434792  0.440234  0.425343\n",
       "1   3.0  0.405833   0.563333  0.617513  0.570063\n",
       "2   5.0  0.375000   0.537408  0.611012  0.551896\n",
       "3   n/a  0.484167   0.638940  0.696369  0.644686"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% Compute metrics\n",
    "\n",
    "metrics_df = pd.concat((\n",
    "    results_df,\n",
    "    pd.DataFrame(\n",
    "        results_df.apply(lambda row: calculate_metrics(str(row[\"prediction\"]), str(row[\"answer\"])), axis=1).tolist(),\n",
    "        columns=(\"Precision\", \"Recall\", \"F1\")\n",
    "    )),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"EM\": results_df.groupby(\"top_k\").apply(\n",
    "        lambda df: exact_match.compute(\n",
    "            predictions=df[\"prediction\"].tolist(),\n",
    "            references=df[\"answer\"].tolist(),\n",
    "            ignore_case=True,\n",
    "            ignore_punctuation=True,\n",
    "        ).get(\"exact_match\")\n",
    "    ),\n",
    "    **metrics_df.groupby(\"top_k\").mean(numeric_only=True),\n",
    "}).reset_index()\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "top_k & EM & Precision & Recall & F1 \\\\\n",
      "\\midrule\n",
      "1.0 & 0.3358 & 0.4348 & 0.4402 & 0.4253 \\\\\n",
      "3.0 & 0.4058 & 0.5633 & 0.6175 & 0.5701 \\\\\n",
      "5.0 & 0.3750 & 0.5374 & 0.6110 & 0.5519 \\\\\n",
      "n/a & 0.4842 & 0.6389 & 0.6964 & 0.6447 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics_df.to_latex(float_format=\"%.4f\", index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
